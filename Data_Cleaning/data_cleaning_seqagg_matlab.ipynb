{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd() + '\\\\' + 'data'\n",
    "files = os.listdir(directory)\n",
    "dfs = {}\n",
    "dfs_standard = {}\n",
    "dfs_sequential = {}\n",
    "for filename in files: # read all the files\n",
    "    if filename.endswith('.csv'):\n",
    "        #concast the file name\n",
    "        dir_filename = \"data/\"+filename\n",
    "        f = pd.read_csv(dir_filename, index_col = 0)        \n",
    "        dfs[filename] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in dfs:\n",
    "\n",
    "    # get the features of df\n",
    "    df_name = name\n",
    "    df_name = df_name.split('.')[0].split('_')\n",
    "    Student_level = df_name[0]\n",
    "    First_gen_status = df_name[1]\n",
    "    Enrollment_status = df_name[2]\n",
    "    Gender = df_name[3]\n",
    "    Residency = df_name[4]\n",
    "    Entry_status = df_name[5]\n",
    "    \n",
    "    \n",
    "    # operation for datasets\n",
    "    df = dfs[name]\n",
    "\n",
    "    # drop broad cat\n",
    "    df = df.drop('Broad category', axis = 1)\n",
    "    # set cat as index \n",
    "    df = df.set_index('Category')\n",
    "\n",
    "    # transpose\n",
    "    df = df.T\n",
    "    df = df.rename_axis(None, axis = 1).rename_axis('Year', axis = 0)\n",
    "    # cat we want\n",
    "    options_cat = [\"African American/Black\", \"African\", \"Other African American/Black\", \"Caribbean\", \"American Indian/Alaska Native\", \"Filipino\", \"Chinese\", \"Asian Indian\", \"Vietnamese\", \"Japanese\", \"Pakistani\", \"Korean\", \"Other Asian\", \"Taiwanese\", \"Indonesian\", \"Thai\", \"Bangladeshi\", \"Cambodian\", \"Malaysian\", \"Mexican/Mexican American/Chicano\", \"Latin American/Latino\", \"Other Spanish American/Latino\", \"Puerto Rican\", \"Cuban\", \"Native Hawaiian and Pacific Islander\", \"Southwest Asian/North African\", \"White/Caucasian\", \"Other White\"]\n",
    "    for i in options_cat:\n",
    "        if i not in df.columns:\n",
    "            df[i] = 0\n",
    "\n",
    "    # first-gen column\n",
    "    if (First_gen_status == 'first'):\n",
    "        df[\"First_gen\"] = 1\n",
    "    elif (First_gen_status == 'nFirst'):\n",
    "        df['First_gen'] = 0\n",
    "        \n",
    "    # gender column\n",
    "    if (Gender == 'fem'):\n",
    "        df[\"Female\"] = 1\n",
    "    elif (Gender == 'male'):\n",
    "        df['Female'] = 0\n",
    "        \n",
    "\n",
    "#     df = df.reset_index()\n",
    "#     # store the dataframes into df_standard    \n",
    "\n",
    "#     # melt the dataset\n",
    "#     columns = df.columns # get all the columns' names\n",
    "#     columns = columns[1:] # get the columns names except for Year\n",
    "\n",
    "#     df = pd.melt(df, id_vars=[\"year\"], value_vars=columns)\n",
    "#     df = df.rename(columns = {0:'Race', 'value':'count'})\n",
    "\n",
    "#     # add columns for other features\n",
    "    # df[\"Student_Level\"] = Student_level\n",
    "    # df[\"First_gen_status\"] = First_gen_status\n",
    "    # df[\"Enrollment_status\"] = Enrollment_status\n",
    "    # df[\"Gender\"] = Gender\n",
    "    # df[\"Residency\"] = Residency\n",
    "    # df[\"Entry_status\"] = Entry_status\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-2:] + options_cat\n",
    "    df = df[cols]\n",
    "    dfs_standard[name] = df\n",
    "\n",
    "# ##################### merge the datasets ########################################\n",
    "\n",
    "names = list(dfs_standard.keys())\n",
    "datasets = list(dfs_standard.values())\n",
    "# # concat all the datasets together\n",
    "df_standard = pd.concat(datasets, sort=False, ignore_index = False)\n",
    "# df_standard = df_standard.sort_values(by = ['year','Student_Level','Residency','Enrollment_status','Gender'])\n",
    "# df_standard = df_standard.reset_index().drop(['index'], axis = 1)\n",
    "# df_standard = df_standard.rename(columns = {'variable':'race'})\n",
    "# df_standard.columns= df_standard.columns.str.lower()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = df_standard.groupby(['Year','First_gen', 'Female']).agg(['sum'])\n",
    "df_standard.to_csv('exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['First_gen', 'Female', 'African American/Black', 'African',\n",
       "       'Other African American/Black', 'Caribbean',\n",
       "       'American Indian/Alaska Native', 'Filipino', 'Chinese', 'Asian Indian',\n",
       "       'Vietnamese', 'Japanese', 'Pakistani', 'Korean', 'Other Asian',\n",
       "       'Taiwanese', 'Indonesian', 'Thai', 'Bangladeshi', 'Cambodian',\n",
       "       'Malaysian', 'Mexican/Mexican American/Chicano',\n",
       "       'Latin American/Latino', 'Other Spanish American/Latino',\n",
       "       'Puerto Rican', 'Cuban', 'Native Hawaiian and Pacific Islander',\n",
       "       'Southwest Asian/North African', 'White/Caucasian', 'Other White'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('CleanedData.csv', index_col = 0)  \n",
    "SANA = ['White/Middle Eastern','Iranian','Armenian', 'Syrian','Israeli', 'Jordanian', 'Turkish', 'Iraqi',\n",
    "        'Lebanese','Palestinian', 'Afghan', 'Egyptian', 'Yemeni','Assyrian/Chaldean', 'White/North African',\n",
    "        'Azerbaijani', 'Kurdish','Algerian','Georgian','Moroccan', 'Circassian','Libyan',\n",
    "        'Sudanese','Other Southwest Asian','Qatari', 'Saudi Arabian']\n",
    "df[\"Southwest Asian/North African\"] = df[SANA].sum(axis =1 )\n",
    "df = df.drop(SANA ,axis =1 )\n",
    "\n",
    "NHPI = ['Hawaiian', 'Fijian', 'Guamanian/Chamoro', 'Samoan', 'Tongan','Other Pacific Islander', 'Hawaii Other Pacific Islander']\n",
    "\n",
    "df['Native Hawaiian and Pacific Islander'] = df[NHPI].sum(axis =1 )\n",
    "df = df.drop(NHPI ,axis =1 )\n",
    "\n",
    "\n",
    "options_cat = ['First_gen',\t'New_Enrollment',\t'Female','CA_residence',\t'Non_CA_residence',\t'International',\n",
    "\"African American/Black\", \"African\", \"Other African American/Black\", \"Caribbean\", \"American Indian/Alaska Native\", \"Filipino\", \"Chinese\", \"Asian Indian\", \"Vietnamese\", \"Japanese\", \"Pakistani\", \"Korean\", \"Other Asian\", \"Taiwanese\", \"Indonesian\", \"Thai\", \"Bangladeshi\", \"Cambodian\", \"Malaysian\", \"Mexican/Mexican American/Chicano\", \"Latin American/Latino\", \"Other Spanish American/Latino\", \"Puerto Rican\", \"Cuban\", \"Native Hawaiian and Pacific Islander\", \"Southwest Asian/North African\", \"White/Caucasian\", \"Other White\"]\n",
    "\n",
    "df = df[options_cat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('exp2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('fullcombo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2a736f2b245f4d7bc218b80048c82ceb23b183a7b82259fe09748f43e77e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
