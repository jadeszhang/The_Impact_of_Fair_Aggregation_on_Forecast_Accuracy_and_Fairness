{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sdv.timeseries import PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = pd.read_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_1/f_model_1.csv')\n",
    "df_enroll = pd.read_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_1/e_model_1.csv')\n",
    "ref = pd.read_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/female.csv', sep=\"\\t\",encoding=\"utf-16-le\", thousands=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['year'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26240/3714324449.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make year index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_enroll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_enroll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_enroll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_enroll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%m-%d-%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_enroll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_enroll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_enroll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_enroll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5451\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5453\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['year'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# make year index \n",
    "df_enroll = df_enroll.set_index('year')\n",
    "df_enroll.index = pd.to_datetime(df_enroll.index, format='%m/%d/%Y')\n",
    "df_enroll = df_enroll.to_period(\"Y\")\n",
    "df_enroll = df_enroll.to_timestamp()\n",
    "\n",
    "df_female = df_female.set_index('year')\n",
    "df_female.index = pd.to_datetime(df_female.index, format='%m/%d/%Y')\n",
    "df_female = df_female.to_period(\"Y\")\n",
    "df_female = df_female.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the broad cats\n",
    "race_std_agg_cats = {'African American and Black': 'a_race_0', \n",
    "                       'Hispanic/Latinx': 'a_race_1',\n",
    "                       'American Indian/Alaska Native': 'a_race_2',\n",
    "                       'Asian': 'a_race_4',\n",
    "                       'Native Hawaiian and Pacific Islander': 'a_race_3',\n",
    "                       'Southwest Asian/North African': 'a_race_5',\n",
    "                       'White': 'a_race_6'}\n",
    "####### define the detailes cats (for model_2 set)\n",
    "cat_agg_disagg_match = {}\n",
    "for race in race_std_agg_cats:\n",
    "    cat_agg_disagg_match[race_std_agg_cats[race]] = []\n",
    "# search all the disaggregate race cats in each dataset\n",
    "for agg_race in race_std_agg_cats:\n",
    "    l_1 = list(ref.loc[ref['Broad category'] == agg_race]['Category'].unique())\n",
    "    cat_agg_disagg_match[race_std_agg_cats[agg_race]] = cat_agg_disagg_match[race_std_agg_cats[agg_race]] + l_1\n",
    "# clean the cat match\n",
    "for disagg_race in cat_agg_disagg_match:\n",
    "    l_2 = cat_agg_disagg_match[disagg_race]\n",
    "    cat_agg_disagg_match[disagg_race] = list(np.unique(np.array(l_2)))\n",
    "\n",
    "l_race = list(df_enroll.columns)\n",
    "# initialize directory for race and indexes\n",
    "race_disagg_cats = {}\n",
    "for i in range(0, len(l_race)):\n",
    "    name = \"race_\" + str(i)\n",
    "    race_disagg_cats[name] = l_race[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_race_0': ['African',\n",
       "  'African American/Black',\n",
       "  'Caribbean',\n",
       "  'Other African American/Black'],\n",
       " 'a_race_1': ['Cuban',\n",
       "  'Latin American/Latino',\n",
       "  'Mexican/Mexican American/Chicano',\n",
       "  'Other Spanish American/Latino',\n",
       "  'Puerto Rican'],\n",
       " 'a_race_2': ['American Indian/Alaska Native'],\n",
       " 'a_race_4': ['Asian Indian',\n",
       "  'Bangladeshi',\n",
       "  'Cambodian',\n",
       "  'Chinese',\n",
       "  'Filipino',\n",
       "  'Hmong',\n",
       "  'Indonesian',\n",
       "  'Japanese',\n",
       "  'Korean',\n",
       "  'Laotian',\n",
       "  'Malaysian',\n",
       "  'Other Asian',\n",
       "  'Pakistani',\n",
       "  'Sri Lankan',\n",
       "  'Taiwanese',\n",
       "  'Thai',\n",
       "  'Vietnamese'],\n",
       " 'a_race_3': ['Fijian',\n",
       "  'Guamanian/Chamoro',\n",
       "  'Hawaii Other Pacific Islander',\n",
       "  'Hawaiian',\n",
       "  'Other Pacific Islander',\n",
       "  'Samoan',\n",
       "  'Tongan'],\n",
       " 'a_race_5': ['Afghan',\n",
       "  'Algerian',\n",
       "  'Armenian',\n",
       "  'Assyrian/Chaldean',\n",
       "  'Azerbaijani',\n",
       "  'Bahraini',\n",
       "  'Berber',\n",
       "  'Circassian',\n",
       "  'Egyptian',\n",
       "  'Emerati',\n",
       "  'Georgian',\n",
       "  'Iranian',\n",
       "  'Iraqi',\n",
       "  'Israeli',\n",
       "  'Jordanian',\n",
       "  'Kurdish',\n",
       "  'Kuwaiti',\n",
       "  'Lebanese',\n",
       "  'Libyan',\n",
       "  'Mauritanian',\n",
       "  'Moroccan',\n",
       "  'Other North African',\n",
       "  'Other Southwest Asian',\n",
       "  'Palestinian',\n",
       "  'Qatari',\n",
       "  'Saudi Arabian',\n",
       "  'Somali',\n",
       "  'Sudanese',\n",
       "  'Syrian',\n",
       "  'Tunisian',\n",
       "  'Turkish',\n",
       "  'White/Middle Eastern',\n",
       "  'Yemeni'],\n",
       " 'a_race_6': ['Other White', 'White/Caucasian']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_agg_disagg_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {w: k for k, v in cat_agg_disagg_match.items() for w in v}\n",
    "df_female_2 = df_female.groupby(by=match,axis=1).sum() \n",
    "df_female_2 = pd.concat([df_female_2, df_female], axis=1, join=\"inner\")\n",
    "# replace the names of disaggregate race\n",
    "d_swap = {v: k for k, v in race_disagg_cats.items()}\n",
    "df_female_2.rename(columns = d_swap, inplace = True)\n",
    "df_female_2.to_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_2/f_model_2.csv')\n",
    "\n",
    "match = {w: k for k, v in cat_agg_disagg_match.items() for w in v}\n",
    "df_enroll_2 = df_enroll.groupby(by=match,axis=1).sum() \n",
    "df_enroll_2 = pd.concat([df_enroll_2, df_enroll], axis=1, join=\"inner\")\n",
    "# replace the names of disaggregate race\n",
    "d_swap = {v: k for k, v in race_disagg_cats.items()}\n",
    "df_enroll_2.rename(columns = d_swap, inplace = True)\n",
    "df_enroll_2.to_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_2/e_model_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_swap = {v: k for k, v in race_disagg_cats.items()}\n",
    "df_enroll.rename(columns = d_swap, inplace = True)\n",
    "df_female.rename(columns = d_swap, inplace = True)\n",
    "df_enroll.to_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_1/e_model_1.csv')\n",
    "df_female.to_csv('C:/Users/Shuyu/Documents/research/OneDrive/research/Forecasting Paper/Data/enrollment_gender/model_1/f_model_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
